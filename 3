import re
import string
from nltk.tokenize import word_tokenize
import nltk

nltk.download('punkt')
nltk.download('punkt_tab')

sentences = [
    "I absolutely love this amazing product!",
    "The service was terrible and disappointing...",
    "Just another ordinary day at work :)",
    "This movie exceeded all my expectations!!!",
    "The food made me sick and I'll never return :(",
    "The weather is quite pleasant today.",
    "I lost my wallet and had the worst day ever!!!",
    "Thank you for making my birthday special! <3",
    "The hotel room was dirty and overpriced...",
    "My new job brings me so much joy!"
]

labels = [
    "positive",
    "negative",
    "neutral",
    "positive",
    "negative",
    "positive",
    "negative",
    "positive",
    "negative",
    "positive"
]

def preprocess_text(text):
    text = text.lower()

    text = re.sub(r'[^\w\s]', '', text)

    text = ' '.join(text.split())

    tokens = word_tokenize(text)
    
    return tokens

preprocessed_dataset = []
for sentence, label in zip(sentences, labels):
    preprocessed_tokens = preprocess_text(sentence)
    preprocessed_dataset.append((preprocessed_tokens, label))

for tokens, label in preprocessed_dataset[:3]:
    print(f"Original text: {sentences[preprocessed_dataset.index((tokens, label))]}")
    print(f"Preprocessed tokens: {tokens}")
    print(f"Sentiment: {label}")
    print()
